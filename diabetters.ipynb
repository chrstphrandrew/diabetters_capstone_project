{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXlr3qYVvkVK",
        "outputId": "9f5766cb-38af-48f5-e1fc-edc78da529cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FZ8qwYEgv2_0"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "dataset = pd.read_csv(url, header=None, names=column_names)\n",
        "\n",
        "# Separate features and target\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dFWXWKgIv5ky"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hp.Int('units1', min_value=64, max_value=512, step=32), input_shape=(X.shape[1],),\n",
        "                    activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout1', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(hp.Int('units2', min_value=64, max_value=512, step=32), activation='relu',\n",
        "                    kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout2', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(hp.Int('units3', min_value=64, max_value=512, step=32), activation='relu',\n",
        "                    kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout3', 0.1, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(hp.Float('learning_rate', 1e-5, 1e-2, sampling='LOG')),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TidbxRLBv8Kg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_dir\\pima_diabetes\\tuner0.json\n"
          ]
        }
      ],
      "source": [
        "# Initialize Keras Tuner\n",
        "tuner = RandomSearch(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_trials=30,\n",
        "                     executions_per_trial=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='pima_diabetes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "de2w1jnwv91e"
      },
      "outputs": [],
      "source": [
        "# Prepare K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store results from each fold\n",
        "fold_accuracies = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3tkXthmwAkc",
        "outputId": "fc351ea5-3a1e-4c1e-9da8-c94a8289ac99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 2s 19ms/step - loss: 1.2694 - accuracy: 0.6792 - val_loss: 1.0675 - val_accuracy: 0.6753 - lr: 0.0042\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.1132 - accuracy: 0.7248 - val_loss: 1.0606 - val_accuracy: 0.6818 - lr: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\BANGKIT\\capstone\\diabetters_capstone_project\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0744 - accuracy: 0.7443 - val_loss: 1.0463 - val_accuracy: 0.6948 - lr: 0.0042\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9905 - accuracy: 0.7590 - val_loss: 1.0271 - val_accuracy: 0.7013 - lr: 0.0042\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9664 - accuracy: 0.7590 - val_loss: 1.0261 - val_accuracy: 0.6883 - lr: 0.0042\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.9314 - accuracy: 0.7638 - val_loss: 0.9906 - val_accuracy: 0.6883 - lr: 0.0042\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9013 - accuracy: 0.7769 - val_loss: 0.9704 - val_accuracy: 0.6883 - lr: 0.0042\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.8734 - accuracy: 0.7736 - val_loss: 0.9236 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8178 - accuracy: 0.7997 - val_loss: 0.9216 - val_accuracy: 0.7078 - lr: 0.0042\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7981 - accuracy: 0.8274 - val_loss: 0.8955 - val_accuracy: 0.7338 - lr: 0.0042\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8064 - accuracy: 0.7801 - val_loss: 0.8687 - val_accuracy: 0.7403 - lr: 0.0042\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7702 - accuracy: 0.7964 - val_loss: 0.8775 - val_accuracy: 0.7143 - lr: 0.0042\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7437 - accuracy: 0.8013 - val_loss: 0.8415 - val_accuracy: 0.7273 - lr: 0.0042\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.8127 - val_loss: 0.8178 - val_accuracy: 0.7078 - lr: 0.0042\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6992 - accuracy: 0.8225 - val_loss: 0.8042 - val_accuracy: 0.7338 - lr: 0.0042\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.7980 - val_loss: 0.8098 - val_accuracy: 0.7403 - lr: 0.0042\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6844 - accuracy: 0.7948 - val_loss: 0.7862 - val_accuracy: 0.7922 - lr: 0.0042\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.7948 - val_loss: 0.7753 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.8127 - val_loss: 0.7692 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.8078 - val_loss: 0.7745 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.8160 - val_loss: 0.8134 - val_accuracy: 0.7208 - lr: 0.0042\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6597 - accuracy: 0.8062 - val_loss: 0.7488 - val_accuracy: 0.7857 - lr: 0.0042\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.7932 - val_loss: 0.7605 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.8241 - val_loss: 0.7529 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6311 - accuracy: 0.7964 - val_loss: 0.7876 - val_accuracy: 0.7273 - lr: 0.0042\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.8094 - val_loss: 0.7591 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.8274 - val_loss: 0.7551 - val_accuracy: 0.7273 - lr: 0.0042\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.8241 - val_loss: 0.7522 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5598 - accuracy: 0.8469 - val_loss: 0.7361 - val_accuracy: 0.7727 - lr: 8.4483e-04\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5664 - accuracy: 0.8274 - val_loss: 0.7417 - val_accuracy: 0.7662 - lr: 8.4483e-04\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5739 - accuracy: 0.8127 - val_loss: 0.7259 - val_accuracy: 0.7662 - lr: 8.4483e-04\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5277 - accuracy: 0.8518 - val_loss: 0.7212 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.8502 - val_loss: 0.7266 - val_accuracy: 0.7468 - lr: 8.4483e-04\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.8371 - val_loss: 0.7157 - val_accuracy: 0.7468 - lr: 8.4483e-04\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.8502 - val_loss: 0.7423 - val_accuracy: 0.7143 - lr: 8.4483e-04\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.8436 - val_loss: 0.7323 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.8453 - val_loss: 0.7513 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.8550 - val_loss: 0.7607 - val_accuracy: 0.7208 - lr: 8.4483e-04\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.8420 - val_loss: 0.7631 - val_accuracy: 0.7338 - lr: 8.4483e-04\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.8583 - val_loss: 0.7664 - val_accuracy: 0.7338 - lr: 1.6897e-04\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.8632 - val_loss: 0.7699 - val_accuracy: 0.7273 - lr: 1.6897e-04\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8697 - val_loss: 0.7762 - val_accuracy: 0.7208 - lr: 1.6897e-04\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.8616 - val_loss: 0.7731 - val_accuracy: 0.7403 - lr: 1.6897e-04\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.8534 - val_loss: 0.7733 - val_accuracy: 0.7403 - lr: 1.6897e-04\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - 2s 14ms/step - loss: 1.1752 - accuracy: 0.6987 - val_loss: 1.0652 - val_accuracy: 0.7468 - lr: 0.0042\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.0817 - accuracy: 0.7280 - val_loss: 1.0460 - val_accuracy: 0.7468 - lr: 0.0042\n",
            "Epoch 3/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.9759 - accuracy: 0.7188"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\BANGKIT\\capstone\\diabetters_capstone_project\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 7ms/step - loss: 1.0078 - accuracy: 0.7557 - val_loss: 1.0131 - val_accuracy: 0.7143 - lr: 0.0042\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9737 - accuracy: 0.7638 - val_loss: 0.9896 - val_accuracy: 0.7078 - lr: 0.0042\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9563 - accuracy: 0.7720 - val_loss: 0.9735 - val_accuracy: 0.7143 - lr: 0.0042\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9104 - accuracy: 0.7769 - val_loss: 0.9331 - val_accuracy: 0.7208 - lr: 0.0042\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.8707 - accuracy: 0.7866 - val_loss: 0.9163 - val_accuracy: 0.7403 - lr: 0.0042\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8489 - accuracy: 0.7769 - val_loss: 0.9055 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.8242 - accuracy: 0.7687 - val_loss: 0.8559 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8103 - accuracy: 0.7671 - val_loss: 0.8511 - val_accuracy: 0.7338 - lr: 0.0042\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7872 - accuracy: 0.7752 - val_loss: 0.8310 - val_accuracy: 0.7273 - lr: 0.0042\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7584 - accuracy: 0.7899 - val_loss: 0.7824 - val_accuracy: 0.7792 - lr: 0.0042\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7113 - accuracy: 0.8176 - val_loss: 0.7997 - val_accuracy: 0.7857 - lr: 0.0042\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7032 - accuracy: 0.7899 - val_loss: 0.7562 - val_accuracy: 0.8052 - lr: 0.0042\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6963 - accuracy: 0.7866 - val_loss: 0.7509 - val_accuracy: 0.7857 - lr: 0.0042\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6759 - accuracy: 0.8143 - val_loss: 0.7413 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6731 - accuracy: 0.8062 - val_loss: 0.7067 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.7834 - val_loss: 0.7121 - val_accuracy: 0.7857 - lr: 0.0042\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.7980 - val_loss: 0.7070 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7117 - accuracy: 0.7492 - val_loss: 0.7162 - val_accuracy: 0.7792 - lr: 0.0042\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.7915 - val_loss: 0.6973 - val_accuracy: 0.7857 - lr: 0.0042\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.8127 - val_loss: 0.6983 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6165 - accuracy: 0.8176 - val_loss: 0.6957 - val_accuracy: 0.7468 - lr: 0.0042\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6355 - accuracy: 0.7980 - val_loss: 0.6711 - val_accuracy: 0.7987 - lr: 0.0042\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.7964 - val_loss: 0.6442 - val_accuracy: 0.8247 - lr: 0.0042\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5996 - accuracy: 0.8127 - val_loss: 0.6736 - val_accuracy: 0.7987 - lr: 0.0042\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.8176 - val_loss: 0.6786 - val_accuracy: 0.7792 - lr: 0.0042\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5852 - accuracy: 0.8241 - val_loss: 0.6778 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.7899 - val_loss: 0.6678 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.8046 - val_loss: 0.6602 - val_accuracy: 0.7857 - lr: 0.0042\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.8355 - val_loss: 0.6671 - val_accuracy: 0.7792 - lr: 8.4483e-04\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.8274 - val_loss: 0.6797 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.8290 - val_loss: 0.6815 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.8453 - val_loss: 0.6826 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.8404 - val_loss: 0.6883 - val_accuracy: 0.7662 - lr: 8.4483e-04\n",
            "5/5 [==============================] - 0s 0s/step\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - 2s 14ms/step - loss: 1.2143 - accuracy: 0.6840 - val_loss: 1.0807 - val_accuracy: 0.6558 - lr: 0.0042\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.0289 - accuracy: 0.7492 - val_loss: 1.1081 - val_accuracy: 0.6234 - lr: 0.0042\n",
            "Epoch 3/100\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0135 - accuracy: 0.7599"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\BANGKIT\\capstone\\diabetters_capstone_project\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0119 - accuracy: 0.7606 - val_loss: 1.1181 - val_accuracy: 0.6039 - lr: 0.0042\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9934 - accuracy: 0.7524 - val_loss: 1.0918 - val_accuracy: 0.6169 - lr: 0.0042\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9351 - accuracy: 0.7785 - val_loss: 1.0560 - val_accuracy: 0.6169 - lr: 0.0042\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9081 - accuracy: 0.7752 - val_loss: 1.0301 - val_accuracy: 0.6169 - lr: 0.0042\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8871 - accuracy: 0.7704 - val_loss: 1.0077 - val_accuracy: 0.6234 - lr: 0.0042\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8742 - accuracy: 0.7769 - val_loss: 0.9593 - val_accuracy: 0.6883 - lr: 0.0042\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8454 - accuracy: 0.7622 - val_loss: 0.9434 - val_accuracy: 0.6948 - lr: 0.0042\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7937 - accuracy: 0.7964 - val_loss: 0.9178 - val_accuracy: 0.6948 - lr: 0.0042\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7846 - accuracy: 0.7883 - val_loss: 0.9082 - val_accuracy: 0.6948 - lr: 0.0042\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7382 - accuracy: 0.7997 - val_loss: 0.9079 - val_accuracy: 0.6558 - lr: 0.0042\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7384 - accuracy: 0.8078 - val_loss: 0.8390 - val_accuracy: 0.7338 - lr: 0.0042\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.8208 - val_loss: 0.8403 - val_accuracy: 0.6948 - lr: 0.0042\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7137 - accuracy: 0.7850 - val_loss: 0.8289 - val_accuracy: 0.7208 - lr: 0.0042\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7022 - accuracy: 0.7964 - val_loss: 0.7925 - val_accuracy: 0.7468 - lr: 0.0042\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.8143 - val_loss: 0.7854 - val_accuracy: 0.7273 - lr: 0.0042\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6690 - accuracy: 0.7834 - val_loss: 0.7655 - val_accuracy: 0.7597 - lr: 0.0042\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.8192 - val_loss: 0.7568 - val_accuracy: 0.7597 - lr: 0.0042\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.7964 - val_loss: 0.7533 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.8078 - val_loss: 0.7670 - val_accuracy: 0.7403 - lr: 0.0042\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.8062 - val_loss: 0.7578 - val_accuracy: 0.7403 - lr: 0.0042\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7932 - val_loss: 0.7589 - val_accuracy: 0.7143 - lr: 0.0042\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7850 - val_loss: 0.7616 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5914 - accuracy: 0.8274 - val_loss: 0.7351 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.8208 - val_loss: 0.7374 - val_accuracy: 0.7662 - lr: 0.0042\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.7997 - val_loss: 0.7643 - val_accuracy: 0.7532 - lr: 0.0042\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.8029 - val_loss: 0.7718 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.8208 - val_loss: 0.7508 - val_accuracy: 0.7727 - lr: 0.0042\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.8388 - val_loss: 0.7705 - val_accuracy: 0.7792 - lr: 0.0042\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.8192 - val_loss: 0.7532 - val_accuracy: 0.7922 - lr: 8.4483e-04\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.8420 - val_loss: 0.7502 - val_accuracy: 0.7792 - lr: 8.4483e-04\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.8388 - val_loss: 0.7444 - val_accuracy: 0.7857 - lr: 8.4483e-04\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.8550 - val_loss: 0.7706 - val_accuracy: 0.7597 - lr: 8.4483e-04\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.8388 - val_loss: 0.7485 - val_accuracy: 0.7987 - lr: 8.4483e-04\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - 2s 15ms/step - loss: 1.2130 - accuracy: 0.6943 - val_loss: 1.0009 - val_accuracy: 0.7647 - lr: 0.0042\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.0437 - accuracy: 0.7301 - val_loss: 0.9998 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 3/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.1650 - accuracy: 0.6875"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\BANGKIT\\capstone\\diabetters_capstone_project\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 7ms/step - loss: 1.0213 - accuracy: 0.7626 - val_loss: 0.9950 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9917 - accuracy: 0.7642 - val_loss: 0.9783 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9487 - accuracy: 0.7463 - val_loss: 0.9403 - val_accuracy: 0.7712 - lr: 0.0042\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9118 - accuracy: 0.7756 - val_loss: 0.9555 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8693 - accuracy: 0.7951 - val_loss: 0.9083 - val_accuracy: 0.7582 - lr: 0.0042\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.8749 - accuracy: 0.7821 - val_loss: 0.8880 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8150 - accuracy: 0.7886 - val_loss: 0.8697 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8153 - accuracy: 0.7789 - val_loss: 0.8616 - val_accuracy: 0.7255 - lr: 0.0042\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7703 - accuracy: 0.7772 - val_loss: 0.8251 - val_accuracy: 0.7386 - lr: 0.0042\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7331 - accuracy: 0.7854 - val_loss: 0.7930 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7568 - accuracy: 0.7919 - val_loss: 0.7943 - val_accuracy: 0.7255 - lr: 0.0042\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7202 - accuracy: 0.7984 - val_loss: 0.7856 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6952 - accuracy: 0.7984 - val_loss: 0.7575 - val_accuracy: 0.7386 - lr: 0.0042\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6680 - accuracy: 0.7951 - val_loss: 0.7625 - val_accuracy: 0.7255 - lr: 0.0042\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6696 - accuracy: 0.8033 - val_loss: 0.7700 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6368 - accuracy: 0.8276 - val_loss: 0.7227 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.7870 - val_loss: 0.7179 - val_accuracy: 0.7647 - lr: 0.0042\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.7951 - val_loss: 0.7357 - val_accuracy: 0.7190 - lr: 0.0042\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.7967 - val_loss: 0.7346 - val_accuracy: 0.7124 - lr: 0.0042\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.8179 - val_loss: 0.7274 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.8033 - val_loss: 0.6980 - val_accuracy: 0.7386 - lr: 0.0042\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.7951 - val_loss: 0.7011 - val_accuracy: 0.7582 - lr: 0.0042\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6328 - accuracy: 0.7984 - val_loss: 0.6942 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.8130 - val_loss: 0.6700 - val_accuracy: 0.7778 - lr: 0.0042\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.8146 - val_loss: 0.7619 - val_accuracy: 0.7386 - lr: 0.0042\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.8049 - val_loss: 0.7051 - val_accuracy: 0.7843 - lr: 0.0042\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.8114 - val_loss: 0.7470 - val_accuracy: 0.7190 - lr: 0.0042\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.7935 - val_loss: 0.7308 - val_accuracy: 0.7712 - lr: 0.0042\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.8211 - val_loss: 0.7372 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5894 - accuracy: 0.8195 - val_loss: 0.7230 - val_accuracy: 0.7451 - lr: 8.4483e-04\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.8407 - val_loss: 0.7143 - val_accuracy: 0.7451 - lr: 8.4483e-04\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.8439 - val_loss: 0.7256 - val_accuracy: 0.7386 - lr: 8.4483e-04\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.8569 - val_loss: 0.7295 - val_accuracy: 0.7516 - lr: 8.4483e-04\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.8423 - val_loss: 0.7254 - val_accuracy: 0.7516 - lr: 8.4483e-04\n",
            "5/5 [==============================] - 0s 0s/step\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 15ms/step - loss: 1.1873 - accuracy: 0.7041 - val_loss: 1.0422 - val_accuracy: 0.7124 - lr: 0.0042\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.1191 - accuracy: 0.7024 - val_loss: 1.0379 - val_accuracy: 0.7124 - lr: 0.0042\n",
            "Epoch 3/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.0448 - accuracy: 0.7188"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\BANGKIT\\capstone\\diabetters_capstone_project\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0941 - accuracy: 0.7252 - val_loss: 1.0438 - val_accuracy: 0.6863 - lr: 0.0042\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9780 - accuracy: 0.7610 - val_loss: 1.0230 - val_accuracy: 0.6993 - lr: 0.0042\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9484 - accuracy: 0.7675 - val_loss: 1.0066 - val_accuracy: 0.6928 - lr: 0.0042\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9057 - accuracy: 0.7675 - val_loss: 0.9725 - val_accuracy: 0.7386 - lr: 0.0042\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8996 - accuracy: 0.7756 - val_loss: 0.9412 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8688 - accuracy: 0.7724 - val_loss: 0.9236 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8035 - accuracy: 0.8033 - val_loss: 0.8835 - val_accuracy: 0.7386 - lr: 0.0042\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8199 - accuracy: 0.7919 - val_loss: 0.8666 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7655 - accuracy: 0.7984 - val_loss: 0.8434 - val_accuracy: 0.7124 - lr: 0.0042\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7750 - accuracy: 0.7740 - val_loss: 0.8345 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7194 - accuracy: 0.7870 - val_loss: 0.8062 - val_accuracy: 0.7647 - lr: 0.0042\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6845 - accuracy: 0.8049 - val_loss: 0.7626 - val_accuracy: 0.7778 - lr: 0.0042\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6990 - accuracy: 0.8000 - val_loss: 0.7353 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.7902 - val_loss: 0.7584 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6726 - accuracy: 0.7919 - val_loss: 0.7365 - val_accuracy: 0.7712 - lr: 0.0042\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.8000 - val_loss: 0.7373 - val_accuracy: 0.7778 - lr: 0.0042\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6423 - accuracy: 0.8065 - val_loss: 0.6856 - val_accuracy: 0.7059 - lr: 0.0042\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6432 - accuracy: 0.7967 - val_loss: 0.7186 - val_accuracy: 0.7647 - lr: 0.0042\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6231 - accuracy: 0.7967 - val_loss: 0.6838 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.8081 - val_loss: 0.6894 - val_accuracy: 0.7647 - lr: 0.0042\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6097 - accuracy: 0.8000 - val_loss: 0.6620 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.8114 - val_loss: 0.6780 - val_accuracy: 0.7255 - lr: 0.0042\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6040 - accuracy: 0.8146 - val_loss: 0.6612 - val_accuracy: 0.7255 - lr: 0.0042\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5957 - accuracy: 0.8195 - val_loss: 0.6506 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.8163 - val_loss: 0.6735 - val_accuracy: 0.7451 - lr: 0.0042\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6034 - accuracy: 0.8065 - val_loss: 0.6371 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.8163 - val_loss: 0.6537 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5656 - accuracy: 0.8081 - val_loss: 0.6453 - val_accuracy: 0.7582 - lr: 0.0042\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.8065 - val_loss: 0.6761 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.8341 - val_loss: 0.6519 - val_accuracy: 0.7516 - lr: 0.0042\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.8081 - val_loss: 0.6665 - val_accuracy: 0.7320 - lr: 0.0042\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.8374 - val_loss: 0.6565 - val_accuracy: 0.7386 - lr: 8.4483e-04\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.8374 - val_loss: 0.6489 - val_accuracy: 0.7386 - lr: 8.4483e-04\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.8455 - val_loss: 0.6549 - val_accuracy: 0.7451 - lr: 8.4483e-04\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.8472 - val_loss: 0.6473 - val_accuracy: 0.7255 - lr: 8.4483e-04\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5157 - accuracy: 0.8455 - val_loss: 0.6550 - val_accuracy: 0.7320 - lr: 8.4483e-04\n",
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Search for the best hyperparameters\n",
        "    tuner.search(X_train, y_train, epochs=100, validation_data=(X_test, y_test),\n",
        "                 callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)])\n",
        "\n",
        "    # Get the optimal hyperparameters\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    # Build the model with the optimal hyperparameters\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    # Train the model with the optimal hyperparameters\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[early_stopping, reduce_lr, checkpoint])\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_weights('best_model.h5')\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fold_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LccndSF9wCEM",
        "outputId": "70d844b3-a79c-44fd-b14c-3a272aef0754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy across all folds: 0.7707919531448943\n",
            "Final optimized model saved as 'diabetters.h5'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\BANGKIT\\capstone\\diabetters_capstone_project\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Calculate the mean accuracy across all folds\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "print(f'Mean Accuracy across all folds: {mean_accuracy}')\n",
        "\n",
        "# Save the final model\n",
        "model.save('diabetters.h5')\n",
        "print(\"Final optimized model saved as 'diabetters.h5'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 115ms/step\n",
            "Predicted class for the example input: 1\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the final optimized model\n",
        "final_model = load_model('diabetters.h5')\n",
        "\n",
        "# Example input data for prediction (same preprocessing as training data)\n",
        "example_input = np.array([[11,138,76,0,0,33.2,0.42,35]])\n",
        "example_input = scaler.transform(example_input)\n",
        "\n",
        "# Predict the outcome\n",
        "example_prediction = final_model.predict(example_input)\n",
        "predicted_class = (example_prediction > 0.5).astype(\"int32\")\n",
        "\n",
        "print(f'Predicted class for the example input: {predicted_class[0][0]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
